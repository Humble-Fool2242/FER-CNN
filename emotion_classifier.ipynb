//Installing required libraries

!pip install -qq wandb
!pip install opencv-python
!pip install tensorflow
!pip install portpicker

//Warning if any discrepences happens 
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
import cv2
import subprocess
import os
import time
import wandb
os.environ['WANDB_NOTEBOOK_NAME'] = 'EmotionClassifier'


#importing Libraries

import numpy as np 
import pandas as pd
import keras 
from keras.models import Sequential
from keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

//Loading the FER -2013 data
def load_fer2013(force=False):
    """Load the emotion dataset"""
    if force or not os.path.exists("fer2013"):
        print("Downloading the face emotion dataset...")
        subprocess.check_output(
            "curl -SL https://www.dropbox.com/s/opuvvdv3uligypx/fer2013.tar | tar xz", shell=True)
    print("Loading dataset...")
    if not os.path.exists('face_cache.npz'):
        data = pd.read_csv("fer2013/fer2013.csv")
        pixels = data['pixels'].tolist()
        width, height = 48, 48
        faces = []
        for pixel_sequence in pixels:
            pixs = pixel_sequence.split(' ')
            try:
                face = np.asarray(pixel_sequence.split(
                    ' '), dtype=np.uint8).reshape(width, height)
                face = cv2.resize(face.astype('uint8'), (width, height))
                faces.append(face.astype('float32'))
            except ValueError:
              print("Unable to load face.")

        faces = np.asarray(faces)
        faces = np.expand_dims(faces, -1)
        emotions = pd.get_dummies(data['emotion']).values
        
     //Train test spilt(80:20)
     
        val_faces = faces[int(len(faces) * 0.8):]
        val_emotions = emotions[int(len(faces) * 0.8):]
        train_faces = faces[:int(len(faces) * 0.8)]
        train_emotions = emotions[:int(len(faces) * 0.8)]
        np.savez('face_cache.npz', train_faces=train_faces, train_emotions=train_emotions,
                 val_faces=val_faces, val_emotions=val_emotions)
    cached = np.load('face_cache.npz')

    return cached['train_faces'], cached['train_emotions'], cached['val_faces'], cached['val_emotions']
    
   //calling the above function 
  input_shape = (48, 48, 1)
  x_train, y_train, x_test,y_test = load_fer2013()
  num_samples, num_classes = train_emotions.shape
  
  //Scaling and Normalizing the data:
  x_train = x_train.astype('float32')
  x_test = x_test.astype('float32')
  x_train /= 255
  x_test /= 255
  
  //Creating a sequential model:
model=Sequential()
model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))
model.add(Conv2D(filters=64, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(MaxPool2D(strides=2))
model.add(Dropout(rate=0.25))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(MaxPool2D(strides=2))
model.add(Dropout(rate=0.25))
model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(rate=0.5))
model.add(Dense(7, activation='softmax'))

//Tuning hyperparamters and compiling of model.
lr_schedule =keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0001,decay_steps=10000,decay_rate=1e-6)
adam=Adam(learning_rate=lr_schedule)
model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)


//Training the model

model.fit(x_train,y_train,batch_size=128,epochs=20)

//Predicting the accuracy and loss on test set 
pred=model.evaluate(x_test,y_test,batch_size=128)
print("Loss= "+str(pred[0]))
print("Accuracy"+str(pred[1]))

//Extracting the summary of model
model.summary()

//Predicting on test set.

y_pred=model.predict(x_test)
